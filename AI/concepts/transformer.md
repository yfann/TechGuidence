
## transformer
+ 文字--(tokenization)-->token--(positional embedding)--->vector---attention-->contextualized token embedding

## attention
+ attention weight
    + 找出相关token


## ref
+ [基于transformers的自然语言处理(NLP)入门](https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main)
+ [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)


+ [learn-nlp-with-transformers](https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main/docs/%E7%AF%87%E7%AB%A01-%E5%89%8D%E8%A8%80)

+ [生成式AI導論 2024 transformer](https://www.youtube.com/watch?v=uhNsUCb2fJI&list=PLJV_el3uVTsPz6CTopeRp2L2t4aL_KgiI&index=11)