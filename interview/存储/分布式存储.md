## 分布式存储
+ 分布式存储系统中面临着的首要问题就是如何将大量的数据分布在不同的存储节点上

## 数据分布（key value存储为例）
+ 数据分布算法有两个基本目标：
    + 均匀性(Uniformity) ：不同存储节点的负载应该均衡；
    + 稳定性(Consistency)：每次一个key通过数据分布算法得到的分布结果应该保持基本稳定，即使再有存储节点发生变化的情况下。
    + 需要考虑的问题：
        + 性能可扩展性，这个主要考虑的是算法相对于存储节点规模的时间复杂度，为了整个系统的可扩展性，数据分布算法不应该在集群规模扩大后显著的增加运行时间。
        + 考虑节点异构，实际工程中，不同存储节点之间可能会有很大的性能或容量差异，好的数据分布算法应该能很好的应对这种异构，提供加权的数据均匀。
        + 隔离故障域，为了数据的高可用，数据分布算法应该为每个key找到一组存储节点，这些节点可能提供的是数据的镜像副本，也可能是类似擦除码的副本方式。数据分布算法应该尽量隔离这些副本的故障域，如不同机房、不同机架、不同交换机、不同机器。

<!-- 对key hash后对节点取模 -->
+ 一旦加节点或删除节点，原节点会受影响

<!-- 一致性hash -->
+ 将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。
    + 在添加或删除节点时，只会影响环上的一小部分数据，而不需要迁移大量的数据。
+ 但这有带来均匀性的问题，即使可以将存储节点等距排列，也会在存储节点个数变化时带来数据的不均匀。
    + 为了解决节点分布不均匀的问题，一致性哈希通常使用虚拟节点。即使一个物理节点对应多个虚拟节点，每个虚拟节点在环上占据不同的位置，从而实现更均匀的数据分布。

<!-- 带负载上限的一致性Hash -->
+ 该算法给Hash环上的每个节点一个负载上限为1 + e倍的平均负载，这个e可以自定义，当key在Hash环上顺时针找到合适的节点后，会判断这个节点的负载是否已经到达上限，如果已达上限，则需要继续找之后的节点进行分配。

+ 无论是一致性Hash还是带负载限制的一致性Hash都无法解决节点异构的问题。

<!-- 带虚拟节点的一致性Hash -->
+ 为了解决负载不均匀和异构的问题，可以在一致性Hash的基础上引入虚拟节点，即hash环上的每个节点并不是实际的存储节点，而是一个虚拟节点。实际的存储节点根据其不同的权重，对应一个或多个虚拟节点，所有落到相应虚拟节点上的key都由该存储节点负责。
+ 这个算法的问题在于，一个实际存储节点的加入或退出，会影响多个虚拟节点的重新分配，进而影响很多节点参与到数据迁移中来；另外，实践中将一个虚拟节点重新分配给新的实际节点时需要将这部分数据遍历出来发送给新节点

<!-- 分片 -->
+ 分片将哈希环切割为相同大小的分片，然后将这些分片交给不同的节点负责。注意这里跟上面提到的虚拟节点有着很本质的区别，分片的划分和分片的分配被解耦，一个节点退出时，其所负责的分片并不需要顺时针合并给之后节点，而是可以更灵活的将整个分片作为一个整体交给任意节点，实践中，一个分片多作为最小的数据迁移和备份单位。

+ 解耦
     + 相当于将原先的key到节点的映射拆成两层，需要一个新的机制来进行分片到存储节点的映射，由于分片数相对key空间已经很小并且数量确定，可以更精确地初始设置，并引入中心目录服务来根据节点存活修改分片的映射关系，同时将这个映射信息通知给所有的存储节点和客户端。
     + key -> 分片 -> node

<!-- CRUSH算法 -->

+ 相对于分片的优化：
    + 分片映射信息量：避免中心目录服务和存储节点及客户端之间需要交互大量的分片映射信息，而改由存储节点或客户端自己根据少量且稳定的集群节点拓扑和确定的规则自己计算分片映射。
    + 完善的故障域划分：支持层级的故障域控制，将同一分片的不同副本按照配置划分到不同层级的故障域中。

    
## ref
+ [一文熟知存储 – 从磁盘到文件，到数据库，到分布式环境集中式存储，再到分布式数据库](http://www.zouzhiquan.com/%e4%b8%80%e6%96%87%e7%86%9f%e7%9f%a5%e5%ad%98%e5%82%a8-%e4%bb%8e%e7%a3%81%e7%9b%98%e5%88%b0%e6%96%87%e4%bb%b6%ef%bc%8c%e5%88%b0%e6%95%b0%e6%8d%ae%e5%ba%93%ef%bc%8c%e5%88%b0%e5%88%86%e5%b8%83/)
+ [浅谈分布式存储系统数据分布方法](http://catkang.github.io/2017/12/17/data-placement.html)